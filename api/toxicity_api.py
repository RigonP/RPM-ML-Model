# toxicity_api.py
from flask import Flask, request, jsonify
from flask_cors import CORS
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import pickle
import numpy as np
from googletrans import Translator  # Shto kÃ«tÃ«
import os

app = Flask(__name__)
CORS(app)

# Inicializo pÃ«rkthyesin
translator = Translator()

print("Po ngarkoj modelin...")

# Ngarko modelin dhe tokenizer-in
try:
    model = load_model('toxicity_model.h5')
    print("âœ… Modeli u ngarkua")
    
    with open('tokenizer.pickle', 'rb') as handle:
        tokenizer = pickle.load(handle)
    print("âœ… Tokenizer-i u ngarkua")
    
    with open('config.pickle', 'rb') as handle:
        config = pickle.load(handle)
        max_len = config['max_len']
    print(f"âœ… Konfigurimi u ngarkua (max_len={max_len})")
    
except Exception as e:
    print(f"âŒ Gabim gjatÃ« ngarkimit: {e}")
    raise

def detect_and_translate(text):
    """
    Detekton gjuhÃ«n dhe pÃ«rkthyen nÃ« anglisht nÃ«se Ã«shtÃ« e nevojshme
    """
    try:
        # Detekto gjuhÃ«n
        detection = translator.detect(text)
        detected_lang = detection.lang
        confidence = detection.confidence
        
        print(f"Gjuha e detektuar: {detected_lang} (besueshmÃ«ri: {confidence})")
        
        # NÃ«se nuk Ã«shtÃ« anglisht, pÃ«rkthe
        if detected_lang != 'en':
            translated = translator.translate(text, src=detected_lang, dest='en')
            english_text = translated.text
            print(f"PÃ«rkthyer: {text[:50]}... -> {english_text[:50]}...")
            return english_text, detected_lang
        
        return text, 'en'
    
    except Exception as e:
        print(f"âš ï¸ Gabim nÃ« pÃ«rkthim: {e}. Po pÃ«rdor tekstin origjinal.")
        # NÃ«se ka problem, pÃ«rdor tekstin origjinal
        return text, 'unknown'

@app.route('/health', methods=['GET'])
def health_check():
    """Kontrollo nÃ«se API Ã«shtÃ« aktiv"""
    return jsonify({
        'status': 'healthy',
        'message': 'Toxicity Detection API Ã«shtÃ« aktiv'
    })

@app.route('/predict', methods=['POST'])
def predict_toxicity():
    """Parashiko toksicitetin e njÃ« teksti"""
    try:
        # Merr tekstin nga request
        data = request.json
        original_text = data.get('text', '')
        
        if not original_text:
            return jsonify({'error': 'Nuk u dÃ«rgua asnjÃ« tekst'}), 400
        
        print(f"Po analizoj: {original_text[:50]}...")
        
        # PÃ«rkthe nÃ«se Ã«shtÃ« e nevojshme
        text_to_analyze, detected_language = detect_and_translate(original_text)
        
        # PÃ«rgatit tekstin
        sequence = tokenizer.texts_to_sequences([text_to_analyze])
        padded = pad_sequences(sequence, maxlen=max_len, padding='post')
        
        # BÃ«j parashikimin
        prediction = model.predict(padded, verbose=0)[0][0]
        toxicity_score = float(prediction * 100)
        
        # Vendos pragun nÃ« 80%
        is_toxic = toxicity_score >= 80
        
        result = {
            'toxicity_score': round(toxicity_score, 2),
            'is_toxic': is_toxic,
            'original_text': original_text,
            'analyzed_text': text_to_analyze if detected_language != 'en' else None,
            'detected_language': detected_language,
            'message': 'Teksti Ã«shtÃ« toksik' if is_toxic else 'Teksti Ã«shtÃ« i pranueshÃ«m'
        }
        
        print(f"Rezultati: {toxicity_score:.2f}% - {'TOKSIK' if is_toxic else 'OK'}")
        
        return jsonify(result)
    
    except Exception as e:
        print(f"âŒ Gabim: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/batch-predict', methods=['POST'])
def batch_predict():
    """Analizo shumÃ« tekste njÃ«kohÃ«sisht"""
    try:
        data = request.json
        texts = data.get('texts', [])
        
        if not texts or not isinstance(texts, list):
            return jsonify({'error': 'Duhet tÃ« dÃ«rgoni njÃ« listÃ« tekstesh'}), 400
        
        results = []
        for original_text in texts:
            # PÃ«rkthe nÃ«se Ã«shtÃ« e nevojshme
            text_to_analyze, detected_language = detect_and_translate(original_text)
            
            sequence = tokenizer.texts_to_sequences([text_to_analyze])
            padded = pad_sequences(sequence, maxlen=max_len, padding='post')
            prediction = model.predict(padded, verbose=0)[0][0]
            toxicity_score = float(prediction * 100)
            
            results.append({
                'original_text': original_text,
                'analyzed_text': text_to_analyze if detected_language != 'en' else None,
                'detected_language': detected_language,
                'toxicity_score': round(toxicity_score, 2),
                'is_toxic': toxicity_score >= 90
            })
        
        return jsonify({'results': results})
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    print("\n" + "="*50)
    print("ğŸš€ Toxicity Detection API Ã«shtÃ« duke u nisur...")
    print("ğŸŒ Suporton tÃ« gjitha gjuhÃ«t (me pÃ«rkthim automatik)")
    print("="*50)
    print("ğŸ“ URL: http://localhost:5000")
    print("ğŸ“ Health Check: http://localhost:5000/health")
    print("ğŸ“ Predict: POST http://localhost:5000/predict")
    print("="*50 + "\n")
    
    app.run(host='0.0.0.0', port=5000, debug=True)